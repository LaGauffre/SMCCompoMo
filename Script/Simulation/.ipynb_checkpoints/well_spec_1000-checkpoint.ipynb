{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb221404-525e-4fd8-8e76-99c3b3e08176",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preamble_scripts.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6c21d-4a4c-42e5-817c-6119f19a74e7",
   "metadata": {},
   "source": [
    "# Simulation study: the well specified case 1000 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "989b767d-d6f6-49ab-9688-ff473598acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "expo = 1000\n",
    "# Setting the true model\n",
    "f1, f2 = bs.loss_model(\"Gamma\", [\"r1\", \"m1\"]), bs.loss_model(\"Lomax\", [\"α2\", \"σ2\"])\n",
    "f_true = bs.spliced_loss_model(f1, f2, \"continuous\")\n",
    "parms_true = np.array([1/2, 1, 2.5, 3, 1.5])\n",
    "f_true.set_ppf(), f_true.set_pdf(),f_true.set_cdf()\n",
    "\n",
    "# We set the priority to the 90% quantile and the limit to the 0.99% quantile\n",
    "P, L = f_true.ppf(parms_true, 0.9), f_true.ppf(parms_true, 0.99)\n",
    "premiums = f_true.PP(parms_true), f_true.XOLP(parms_true, P, L)\n",
    "\n",
    "PnLs = np.array(f_true.PnL(parms_true, P, L, expo, premiums, safety_loadings = [0.05, 0.05], n_sim = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cc7af-dca7-4597-ae6f-c0cbe92b571f",
   "metadata": {},
   "source": [
    "We are interested in the estimations of the extreme quantile of the claim size distribution (of order 0.95, 0.99, 0.995) and the quantile of the aggregate losses over one year with a XOL reinsurance agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9b0c23-e77b-4939-9d9e-043c59cb9b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.99792798, -12.96510848, -12.70255245])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_VaRs = [f_true.ppf(parms_true, prob) for prob in [0.95, 0.99, 0.995]]\n",
    "true_cap = np.quantile(PnLs, [0.005, 0.01, 0.05])\n",
    "true_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7dd2abf5-8de3-4ea8-8f75-29b2e578a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for the bulk distribution\n",
    "body_model_names = [\"Exp\", \"Gamma\", \"Weibull\", \"Lognormal\", \"Inverse-Weibull\", \"Inverse-Gamma\", \"Inverse-Gaussian\", \"Lomax\", \"Log-Logistic\", \"Burr\"]\n",
    "body_model_param_names = [ [\"λ1\"], [\"r1\", \"m1\"], [\"k1\", \"β1\"],\n",
    "                          [\"μ1\", \"σ1\"], [\"k1\", \"β1\"], [\"r1\", \"m1\"], [\"μ1\", \"λ1\"], [\"α1\", \"σ1\"], [\"β1\", \"σ1\"], [\"α1\", \"β1\", \"σ1\"] ]\n",
    "\n",
    "# Prior distributions over the parameters of the bulk distribution\n",
    "body_model_priors= [ \n",
    "    [bs.prior_model('gamma',body_model_param_names[0][0], 1, 1)], \n",
    "     [bs.prior_model('gamma',body_model_param_names[1][0], 1, 1), bs.prior_model('gamma',body_model_param_names[1][1], 1, 1)],\n",
    "    [bs.prior_model('gamma',body_model_param_names[2][0], 1, 1), bs.prior_model('gamma',body_model_param_names[2][1], 1, 1)],\n",
    "    [bs.prior_model('normal',body_model_param_names[3][0], 0, 0.5), bs.prior_model('gamma',body_model_param_names[3][1], 1, 1)],\n",
    "     [bs.prior_model('gamma',body_model_param_names[4][0], 1, 1), bs.prior_model('gamma',body_model_param_names[4][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[5][0], 1, 1), bs.prior_model('gamma',body_model_param_names[5][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[6][0], 1, 1), bs.prior_model('gamma',body_model_param_names[6][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[7][0], 1, 1), bs.prior_model('gamma',body_model_param_names[7][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[8][0], 1, 1), bs.prior_model('gamma',body_model_param_names[8][1], 1, 1)],\n",
    "    [bs.prior_model('gamma',body_model_param_names[9][0], 1, 1), bs.prior_model('gamma',body_model_param_names[9][1], 1, 1), \n",
    "     bs.prior_model('gamma',body_model_param_names[9][2], 1, 1)]\n",
    "]\n",
    "\n",
    "# Model for the tail of the distribution\n",
    "tail_model_names = [\"Weibull\", \"Lognormal\", \"Log-Logistic\", \"Lomax\", \"Burr\", \"Pareto-Tail\", \"GPD-Tail\", \"Inverse-Gamma\", \"Inverse-Weibull\", \"Exp\", \"Gamma\"]\n",
    "\n",
    "tail_model_param_names = [[\"k2\", \"β2\"], [\"μ2\", \"σ2\"], [\"β2\", \"σ2\"], [\"α2\", \"σ2\"], [\"α2\", \"β2\", \"σ2\"], [\"α2\"], [\"ξ2\",\"σ2\"], [\"r2\", \"m2\"], [\"k2\", \"β2\"], [\"λ2\"], [\"r2\", \"m2\"]]\n",
    "\n",
    "# Prior distributions over the parameters of the bulk distribution\n",
    "tail_model_priors= [\n",
    "                [bs.prior_model('gamma',tail_model_param_names[0][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[0][1], 1, 1)],\n",
    "                [bs.prior_model('normal',tail_model_param_names[1][0], 0, 0.5), bs.prior_model('gamma',tail_model_param_names[1][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[2][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[2][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[3][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[3][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[4][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[4][1], 1, 1), bs.prior_model('gamma',tail_model_param_names[4][2], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[5][0], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[6][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[6][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[7][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[7][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[8][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[8][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[9][0], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[10][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[10][1], 1, 1)]\n",
    "]\n",
    "\n",
    "γ_prior = bs.prior_model('gamma',\"γ\", 1, 1)\n",
    "\n",
    "#Splicing model type\n",
    "splicing_types = [\"continuous\"]\n",
    "\n",
    "# Setting the models\n",
    "fs, f_names, prior_spliced_model = [], [], []\n",
    "for i in range(len(body_model_names)):\n",
    "    for j in range(len(tail_model_names)):\n",
    "        for splicing_type in splicing_types:\n",
    "            f1, f2 =  bs.loss_model(body_model_names[i], body_model_param_names[i]), bs.loss_model(tail_model_names[j], tail_model_param_names[j])\n",
    "            fs.append(bs.spliced_loss_model(f1 , f2, splicing_type))\n",
    "            f_names.append(body_model_names[i] +\"_\"+ tail_model_names[j]+\"_\"+splicing_type)\n",
    "            if splicing_type == \"disjoint\": \n",
    "                prior_spliced_model.append(bs.independent_priors(body_model_priors[i] + tail_model_priors[j] + [γ_prior, p_prior]))\n",
    "            else:\n",
    "                prior_spliced_model.append(bs.independent_priors(body_model_priors[i] + tail_model_priors[j] + [γ_prior]))  \n",
    "for f in fs:\n",
    "    f.set_ppf(), f.set_cdf(), f.set_pdf() \n",
    "f_spliced_dic = dict(zip(f_names, fs))\n",
    "prior_dic = dict(zip(f_names, prior_spliced_model))\n",
    "len(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f2d38-e4ba-4ac6-9c73-c87a6cf4c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation #0\n",
      "CPU times: user 3min 40s, sys: 2.16 s, total: 3min 42s\n",
      "Wall time: 3min 50s\n",
      "Simulation #1\n"
     ]
    }
   ],
   "source": [
    "nobs, n_sim = expo, 100\n",
    "Xs = [f_true.sample(parms_true, nobs) for k in range(n_sim)]\n",
    "popSize, ρ, c, n_step_max, err, paralell, n_proc, verbose = 5000, 1/2, 0.99, 25, 1e-6, False, 4, False\n",
    "dfs = []\n",
    "for k in range(n_sim):\n",
    "    print(\"Simulation #\"+str(k))\n",
    "    def fit_spliced_models(i):\n",
    "        trace, log_marg, DIC, WAIC = bs.smc(Xs[k], fs[i], popSize, prior_spliced_model[i], ρ, c,n_step_max, err, paralell, 4, verbose)\n",
    "        VaRs = [fs[i].ppf(trace.mean().values, prob) for prob in [0.95, 0.99, 0.995]]\n",
    "#         premiums = fs[i].PP(trace.mean().values), fs[i].XOLP(trace.mean().values, P, L)\n",
    "#         PnLs = np.array(fs[i].PnL(trace.mean().values, P, L, expo, premiums, safety_loadings = [0.05, 0.05], n_sim = int(1e5)))\n",
    "#         caps = np.quantile(PnLs, [0.005, 0.01, 0.05])\n",
    "        Wass_dist = bs.compute_Wasserstein(Xs[k], fs[i], trace.mean().values, 1)\n",
    "        return(np.array([k, f_names[i], nobs, trace[\"γ\"].mean(), log_marg, Wass_dist] + VaRs))\n",
    "    %time res = Parallel(n_jobs= 40)(delayed(fit_spliced_models)(i) for i in range(len(fs)))\n",
    "    df = pd.DataFrame(res, columns = [\"sim\", \"model_name\", \"nobs\", \"γ_map\", \"log_marg\", \"Wass_dist\", \"q95\", \"q99\", \"q995\"])\n",
    "    df[df.columns[2:]] = df[df.columns[2:]].astype(float)\n",
    "\n",
    "    df[\"posterior_probability\"] = np.exp(df[\"log_marg\"] - np.max(df[\"log_marg\"])) / np.sum(np.exp(df[\"log_marg\"] - np.max(df[\"log_marg\"]))) \n",
    "    dfs.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f49d71f-fc91-4139-8243-b5825bea7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs).to_csv(\"../../Data/Simulations/simu_well_spec_\"+str(expo)+\".csv\", sep=',')\n",
    "with open('../../Data/Simulations/sim_data_'+str(expo)+'.obj', 'wb') as fp:\n",
    "    pickle.dump(Xs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interested-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = pd.concat(dfs)\n",
    "# df_final[[\"model_name\",\"posterior_probability\"]][df_final.model_name == \"Gamma_Lomax_continuous\"].boxplot()\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "apart-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(n_sim):\n",
    "#     best_models= df_final[df_final.sim == str(k)].sort_values(by='log_marg', ascending=False).iloc[:10]\n",
    "#     print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-perfume",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
