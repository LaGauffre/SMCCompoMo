{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30667778-2df4-4b7a-9f47-4a2ed05343d6",
   "metadata": {},
   "source": [
    "# Australian fire insurance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236790f7-bab7-45d4-b1c6-bd1ca1b9ee7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T09:38:14.417249Z",
     "iopub.status.busy": "2022-01-26T09:38:14.416666Z",
     "iopub.status.idle": "2022-01-26T09:38:15.698694Z",
     "shell.execute_reply": "2022-01-26T09:38:15.699454Z"
    }
   },
   "outputs": [],
   "source": [
    "%run preamble_scripts.py\n",
    "ausautoBI8999 = pd.read_csv(\"../../Data/Aus_Auto/ausautoBI8999.csv\")\n",
    "aus = pd.concat([ausautoBI8999[[\"FinDate\", \"FinMth\" ,\"AggClaim\"]], \n",
    "                 pd.DataFrame({'year':np.array([dat.datetime.fromisoformat(ausautoBI8999[\"FinDate\"].iloc[k]).year \n",
    "                                                for k in range(len(ausautoBI8999[\"FinDate\"]))])})\n",
    "                ], axis = 1)\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b5c34-45e0-4c08-af42-2cd6a6d490f7",
   "metadata": {},
   "source": [
    "## Yearly claim frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77151f4f-f495-4f34-ae09-5a8bafc4c93c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T09:38:15.704538Z",
     "iopub.status.busy": "2022-01-26T09:38:15.703675Z",
     "iopub.status.idle": "2022-01-26T09:38:15.712208Z",
     "shell.execute_reply": "2022-01-26T09:38:15.712815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3148.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nb_claim = aus.groupby('year').count()['AggClaim'].reset_index()\n",
    "expo = np.mean(count_nb_claim['AggClaim'])\n",
    "expo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126bb5fa-8d5a-4ba5-a659-1dcc69bcff41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T09:38:15.718813Z",
     "iopub.status.busy": "2022-01-26T09:38:15.718076Z",
     "iopub.status.idle": "2022-01-26T09:38:15.745598Z",
     "shell.execute_reply": "2022-01-26T09:38:15.746198Z"
    }
   },
   "outputs": [],
   "source": [
    "#Rolling mean, median 95 and 99% quantile for years and month\n",
    "Quantities = ['q50', 'q75', 'q95', 'q99']\n",
    "Quantity_labels  = [\"Quantile à $50\\%$\",\n",
    "                   \"Quantile à $75\\%$\",\n",
    "                   \"Quantile à $95\\%$\",\n",
    "                   \"Quantile à $99\\%$\"\n",
    "                  ]\n",
    "aus['scaled_aggclaims'] = aus['AggClaim'] / 1e6 \n",
    "yearly_df = pd.DataFrame({'year':np.unique(aus['year']),\n",
    "                          'q50':aus[['year', \"scaled_aggclaims\"]].groupby('year').quantile(0.5).values.flatten(), \n",
    "                          'q75': aus[['year', \"scaled_aggclaims\"]].groupby('year').quantile(0.75).values.flatten(), \n",
    "                          'q95': aus[['year', \"scaled_aggclaims\"]].groupby('year').quantile(0.95).values.flatten(), \n",
    "                          'q99' : aus[['year', \"scaled_aggclaims\"]].groupby('year').quantile(0.99).values.flatten()}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b8d8a-b3a1-49b8-956a-7878ebe20096",
   "metadata": {},
   "source": [
    "## Spliced loss model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a0bcfb-9f02-4059-bfa8-565ab50f9816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T09:38:15.931691Z",
     "iopub.status.busy": "2022-01-26T09:38:15.901079Z",
     "iopub.status.idle": "2022-01-26T09:38:15.940243Z",
     "shell.execute_reply": "2022-01-26T09:38:15.941058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for the bulk distribution\n",
    "body_model_names = [\"Exp\", \"Gamma\", \"Weibull\", \"Lognormal\", \"Inverse-Weibull\", \"Inverse-Gamma\", \"Inverse-Gaussian\", \"Lomax\", \"Log-Logistic\", \"Burr\"]\n",
    "body_model_param_names = [ [\"λ1\"], [\"r1\", \"m1\"], [\"k1\", \"β1\"],\n",
    "                          [\"μ1\", \"σ1\"], [\"k1\", \"β1\"], [\"r1\", \"m1\"], [\"μ1\", \"λ1\"], [\"α1\", \"σ1\"], [\"β1\", \"σ1\"], [\"α1\", \"β1\", \"σ1\"] ]\n",
    "\n",
    "# Prior distributions over the parameters of the bulk distribution\n",
    "body_model_priors= [ \n",
    "    [bs.prior_model('gamma',body_model_param_names[0][0], 1, 1)], \n",
    "     [bs.prior_model('gamma',body_model_param_names[1][0], 1, 1), bs.prior_model('gamma',body_model_param_names[1][1], 1, 1)],\n",
    "    [bs.prior_model('gamma',body_model_param_names[2][0], 1, 1), bs.prior_model('gamma',body_model_param_names[2][1], 1, 1)],\n",
    "    [bs.prior_model('normal',body_model_param_names[3][0], 0, 0.5), bs.prior_model('gamma',body_model_param_names[3][1], 1, 1)],\n",
    "     [bs.prior_model('gamma',body_model_param_names[4][0], 1, 1), bs.prior_model('gamma',body_model_param_names[4][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[5][0], 1, 1), bs.prior_model('gamma',body_model_param_names[5][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[6][0], 1, 1), bs.prior_model('gamma',body_model_param_names[6][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[7][0], 1, 1), bs.prior_model('gamma',body_model_param_names[7][1], 1, 1)], \n",
    "    [bs.prior_model('gamma',body_model_param_names[8][0], 1, 1), bs.prior_model('gamma',body_model_param_names[8][1], 1, 1)],\n",
    "    [bs.prior_model('gamma',body_model_param_names[9][0], 1, 1), bs.prior_model('gamma',body_model_param_names[9][1], 1, 1), \n",
    "     bs.prior_model('gamma',body_model_param_names[9][2], 1, 1)]\n",
    "]\n",
    "\n",
    "# Model for the tail of the distribution\n",
    "tail_model_names = [\"Weibull\", \"Lognormal\", \"Log-Logistic\", \"Lomax\", \"Burr\", \"Pareto-Tail\", \"GPD-Tail\", \"Inverse-Gamma\", \"Inverse-Weibull\", \"Exp\", \"Gamma\"]\n",
    "\n",
    "tail_model_param_names = [[\"k2\", \"β2\"], [\"μ2\", \"σ2\"], [\"β2\", \"σ2\"], [\"α2\", \"σ2\"], [\"α2\", \"β2\", \"σ2\"], [\"α2\"], [\"ξ2\",\"σ2\"], [\"r2\", \"m2\"], [\"k2\", \"β2\"], [\"λ2\"], [\"r2\", \"m2\"]]\n",
    "\n",
    "# Prior distributions over the parameters of the bulk distribution\n",
    "tail_model_priors= [\n",
    "                [bs.prior_model('gamma',tail_model_param_names[0][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[0][1], 1, 1)],\n",
    "                [bs.prior_model('normal',tail_model_param_names[1][0], 0, 0.5), bs.prior_model('gamma',tail_model_param_names[1][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[2][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[2][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[3][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[3][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[4][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[4][1], 1, 1), bs.prior_model('gamma',tail_model_param_names[4][2], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[5][0], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[6][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[6][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[7][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[7][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[8][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[8][1], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[9][0], 1, 1)],\n",
    "                [bs.prior_model('gamma',tail_model_param_names[10][0], 1, 1), bs.prior_model('gamma',tail_model_param_names[10][1], 1, 1)]\n",
    "]\n",
    "\n",
    "γ_prior = bs.prior_model('gamma',\"γ\", 1, 1)\n",
    "\n",
    "#Splicing model type\n",
    "splicing_types = [\"continuous\"]\n",
    "\n",
    "# Setting the models\n",
    "fs, f_names, prior_spliced_model = [], [], []\n",
    "for i in range(len(body_model_names)):\n",
    "    for j in range(len(tail_model_names)):\n",
    "        for splicing_type in splicing_types:\n",
    "            f1, f2 =  bs.loss_model(body_model_names[i], body_model_param_names[i]), bs.loss_model(tail_model_names[j], tail_model_param_names[j])\n",
    "            fs.append(bs.spliced_loss_model(f1 , f2, splicing_type))\n",
    "            f_names.append(body_model_names[i] +\"_\"+ tail_model_names[j]+\"_\"+splicing_type)\n",
    "            if splicing_type == \"disjoint\": \n",
    "                prior_spliced_model.append(bs.independent_priors(body_model_priors[i] + tail_model_priors[j] + [γ_prior, p_prior]))\n",
    "            else:\n",
    "                prior_spliced_model.append(bs.independent_priors(body_model_priors[i] + tail_model_priors[j] + [γ_prior]))  \n",
    "for f in fs:\n",
    "    f.set_ppf(), f.set_cdf(), f.set_pdf() \n",
    "f_spliced_dic = dict(zip(f_names, fs))\n",
    "prior_dic = dict(zip(f_names, prior_spliced_model))\n",
    "len(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ce917e-5617-4bd3-a518-0a3673fce3f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T09:38:15.953668Z",
     "iopub.status.busy": "2022-01-26T09:38:15.952911Z",
     "iopub.status.idle": "2022-01-26T13:08:20.949967Z",
     "shell.execute_reply": "2022-01-26T13:08:20.950882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993\n",
      "CPU times: user 2min 35s, sys: 904 ms, total: 2min 35s\n",
      "Wall time: 11min 31s\n",
      "1994\n",
      "CPU times: user 2min 51s, sys: 746 ms, total: 2min 51s\n",
      "Wall time: 29min 52s\n",
      "1995\n",
      "CPU times: user 2min 39s, sys: 956 ms, total: 2min 40s\n",
      "Wall time: 31min 19s\n",
      "1996\n",
      "CPU times: user 2min 49s, sys: 852 ms, total: 2min 49s\n",
      "Wall time: 31min 49s\n",
      "1997\n",
      "CPU times: user 3min, sys: 976 ms, total: 3min 1s\n",
      "Wall time: 42min 38s\n",
      "1998\n",
      "CPU times: user 2min 57s, sys: 924 ms, total: 2min 58s\n",
      "Wall time: 53min 36s\n",
      "1999\n",
      "CPU times: user 2min 34s, sys: 596 ms, total: 2min 35s\n",
      "Wall time: 9min 17s\n"
     ]
    }
   ],
   "source": [
    "years = aus.year.drop_duplicates().values\n",
    "dfs = []\n",
    "for year in years:\n",
    "    print(year)\n",
    "    X = aus.scaled_aggclaims.values[aus.year == year]\n",
    "    popSize, ρ, c, n_step_max, err, paralell, n_proc, verbose = 10000, 1/2, 0.99, 25, 1e-6, False, 4, False\n",
    "    def fit_spliced_models(i):\n",
    "        print(f_names[i])\n",
    "        trace, log_marg, DIC, WAIC = bs.smc(X, fs[i], popSize, prior_spliced_model[i], ρ, c,n_step_max, err, paralell, 4, verbose)\n",
    "        VaRs = [fs[i].ppf(trace.mean().values, prob) for prob in [0.95, 0.99, 0.995]]\n",
    "        # premiums = fs[i].PP(trace.mean().values), fs[i].XOLP(trace.mean().values, P, L)\n",
    "        # PnLs = np.array(fs[i].PnL(trace.mean().values, P, L, expo, premiums, safety_loadings = [0.05, 0.05], n_sim = int(1e5)))\n",
    "        # caps = np.quantile(PnLs, [0.005, 0.01, 0.05])\n",
    "        Wass_dist = bs.compute_Wasserstein(X, fs[i], trace.mean().values, 1)\n",
    "        return(np.array([year, f_names[i],trace[\"γ\"].mean(), log_marg, Wass_dist] + VaRs))\n",
    "        \n",
    "\n",
    "    %time res = Parallel(n_jobs= 40)(delayed(fit_spliced_models)(i) for i in range(len(fs)))\n",
    "\n",
    "    df = pd.DataFrame(res, columns = [\"year\", \"model_name\", \"γ_map\",  \"log_marg\", \"Wass_dist\", \"q95\", \"q99\", \"q995\"])\n",
    "    df[df.columns[2:]] = df[df.columns[2:]].astype(float)\n",
    "\n",
    "    df[\"posterior_probability\"] = np.exp(df[\"log_marg\"] - np.max(df[\"log_marg\"])) / np.sum(np.exp(df[\"log_marg\"] - np.max(df[\"log_marg\"]))) \n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e02965-4790-44df-b90d-dbf069ce4a69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T13:08:20.956446Z",
     "iopub.status.busy": "2022-01-26T13:08:20.955368Z",
     "iopub.status.idle": "2022-01-26T13:08:20.972538Z",
     "shell.execute_reply": "2022-01-26T13:08:20.973401Z"
    }
   },
   "outputs": [],
   "source": [
    "spliced_models_df = pd.concat(dfs)\n",
    "spliced_models_df.to_csv(\"../../Data/Aus_Auto/aus_spliced_model_fit.csv\", sep=',')\n",
    "# for year in years:\n",
    "#     X = aus.scaled_aggclaims.values[aus.year == year]\n",
    "#     best_model_name = spliced_models_df[spliced_models_df.year == str(year)].sort_values(by='Wass_dist', ascending=True)[\"model_name\"].values[0]\n",
    "#     # best_model_name = \"Lognormal\"\n",
    "#     print(best_model_name)\n",
    "#     f, prior = f_spliced_dic[best_model_name], prior_dic[best_model_name] \n",
    "#     %time trace, log_marg, DIC, WAIC = bs.smc(X, f, 1000, prior, verbose = True)\n",
    "#     print(log_marg)\n",
    "#     bs.qq_plot(X, f, trace.mean().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d2fdab-e220-4a34-9278-8fbc70a5fa5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T13:08:20.976922Z",
     "iopub.status.busy": "2022-01-26T13:08:20.976154Z",
     "iopub.status.idle": "2022-01-26T13:08:20.978095Z",
     "shell.execute_reply": "2022-01-26T13:08:20.978718Z"
    }
   },
   "outputs": [],
   "source": [
    "# for year in years:\n",
    "#     best_models= spliced_models_df[spliced_models_df.year == str(year)].sort_values(by='Wass_dist', ascending=True).iloc[:5]\n",
    "#     print(best_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a53b5cb-7d08-46a2-8a1e-f4a729958fd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T13:08:20.982018Z",
     "iopub.status.busy": "2022-01-26T13:08:20.981260Z",
     "iopub.status.idle": "2022-01-26T13:08:20.983314Z",
     "shell.execute_reply": "2022-01-26T13:08:20.983942Z"
    }
   },
   "outputs": [],
   "source": [
    "# for year in years:\n",
    "#     X = aus.scaled_aggclaims.values[aus.year == year]\n",
    "#     best_model_thresh = spliced_models_df[spliced_models_df.year == str(year)].sort_values(by='log_marg', ascending=False)[\"γ_map\"].values[0]\n",
    "#     print(np.mean(X < best_model_thresh),best_model_thresh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
