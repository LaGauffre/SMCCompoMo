{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30667778-2df4-4b7a-9f47-4a2ed05343d6",
   "metadata": {},
   "source": [
    "# Danish fire insurance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "236790f7-bab7-45d4-b1c6-bd1ca1b9ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/pgoffard/BayesSplicedModels/')\n",
    "%run ../../preamble.py\n",
    "danish = pd.read_csv(\"../../Data/Danish/danish.csv\").x\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-treasurer",
   "metadata": {},
   "source": [
    "# Martin and Hansjoerg method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "confident-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.781844802"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = danish.values\n",
    "n, k = len(X), 30\n",
    "def compute_Tk(X, k):\n",
    "    n = len(X)\n",
    "    X_sorted = np.sort(X)\n",
    "    Y_k = np.flip(X_sorted[n-k:] / X_sorted[n-1-k])\n",
    "    num = np.cumsum(np.log(Y_k))/np.arange(1, k+1, 1)\n",
    "    denom = 1 + np.flip(np.cumsum(np.flip(np.append(1/np.arange(2, k+1, 1), 0))))\n",
    "    Tk = num / denom \n",
    "    return(Tk)\n",
    "\n",
    "def fp(p):\n",
    "    res = (1-np.exp(1-2*p)*(1-2*p)*sp.exp1(1-2*p)-np.exp(2-2*p)*sp.exp1(1-p)**2) / p**2/ (1-p)**2 + \\\n",
    "    2*(np.exp(2-p)*sp.exp1(1-p)*sp.exp1(1)-1+np.exp(1-p)*(1-p)*sp.exp1(1-p)) / p**2 / (1-p) + \\\n",
    "    (1-np.exp(1)*sp.exp1(1)-np.exp(2)*sp.exp1(1)**2) / p**2\n",
    "    return(res)\n",
    "\n",
    "\n",
    "def optimal_threshold(X, p = -1):\n",
    "    n = len(X)\n",
    "    X_sorted = np.sort(X)\n",
    "    C = 0.502727\n",
    "    emp_var = np.array([np.var(compute_Tk(X, k)) for k in np.arange(2, len(X) - int(len(X)/5), 1)])\n",
    "    k_ast = np.where(emp_var == np.min(emp_var))[0][0]\n",
    "    k0_ast = k_ast * (C / fp(p)/ (1-p)**2)**(-1/(1-2*p))\n",
    "    return(X_sorted[n-1-int(k0_ast)]) \n",
    "\n",
    "optimal_threshold(X, p = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5a3fa-2721-4443-90ae-c558afd7c9b5",
   "metadata": {},
   "source": [
    "# Fitting splicing models to the data with fixed threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ecfe15e-cd2c-46c2-86c8-d016581e2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data\n",
    "X = danish.values\n",
    "# Model for the bulk distribution\n",
    "body_model_names = [\"Log-Logistic\", \"Lomax\", \"Burr\", \"Exp\", \"Gamma\", \"Weibull\", \"Inverse-Gaussian\", \"Lognormal\", \"Inverse-Weibull\"]\n",
    "body_model_param_names = [[\"β1\", \"σ1\"], [\"α1\", \"σ1\"], [\"α1\",\"β1\", \"σ1\"], [\"λ1\"], [\"r1\", \"m1\"], [\"k1\", \"β1\"],[\"μ1\", \"λ1\"],\n",
    "                          [\"μ1\", \"σ1\"], [\"k1\", \"β1\"]]\n",
    "\n",
    "# Prior distributions over the parameters of the bulk distribution\n",
    "body_model_priors= [\n",
    "                [bsm.prior_model('gamma',body_model_param_names[0][0], 1, 1), \n",
    "                 bsm.prior_model('gamma',body_model_param_names[0][1], 1, 1)],\n",
    "    [bsm.prior_model('gamma',body_model_param_names[1][0], 1, 1), \n",
    "     bsm.prior_model('gamma',body_model_param_names[1][1], 1, 1)],\n",
    "    [bsm.prior_model('gamma',body_model_param_names[2][0], 1, 1), \n",
    "     bsm.prior_model('gamma',body_model_param_names[2][1], 1, 1),\n",
    "     bsm.prior_model('gamma',body_model_param_names[2][2], 1, 1)], \n",
    "    [bsm.prior_model('gamma',body_model_param_names[3][0], 1, 1)], \n",
    "     [bsm.prior_model('gamma',body_model_param_names[4][0], 1, 1),\n",
    "     bsm.prior_model('gamma',body_model_param_names[4][1], 1, 1)],\n",
    "    [bsm.prior_model('gamma',body_model_param_names[5][0], 1, 1),\n",
    "     bsm.prior_model('gamma',body_model_param_names[5][1], 1, 1)],\n",
    "    [bsm.prior_model('gamma',body_model_param_names[6][0], 1, 1),\n",
    "     bsm.prior_model('gamma',body_model_param_names[6][1], 1, 1)],\n",
    "    [bsm.prior_model('normal',body_model_param_names[7][0], 0, 0.5),\n",
    "     bsm.prior_model('gamma',body_model_param_names[7][1], 1, 1)],\n",
    "     [bsm.prior_model('gamma',body_model_param_names[8][0], 1, 1),\n",
    "     bsm.prior_model('gamma',body_model_param_names[8][1], 1, 1)]\n",
    "]\n",
    "# Model for the tail of the distribution\n",
    "tail_model_names = [\"Pareto-Tail\", \"GPD-Tail\"]\n",
    "\n",
    "\n",
    "tail_model_param_names = [ [\"α2\"], [\"ξ2\",\"σ2\"]]\n",
    "\n",
    "# Prior distributions over the parameters of the bulk distribution\n",
    "tail_model_priors= [\n",
    "                [bsm.prior_model('gamma',tail_model_param_names[0][0], 1, 1)],\n",
    "                [bsm.prior_model('gamma',tail_model_param_names[1][0], 1, 1), bsm.prior_model('gamma',tail_model_param_names[1][1], 1, 1)]\n",
    "]\n",
    "             \n",
    "γ_prior, p_prior = bsm.prior_model('fixed', \"γ\", optimal_threshold(X, p = -1), max(X)), bsm.prior_model('uniform',\"p\", 0, 1)\n",
    "\n",
    "#Splicing model type\n",
    "splicing_types = [\"disjoint\", \"simple\", \"continuous\"]\n",
    "\n",
    "# Setting the models\n",
    "fs, f_names, prior_spliced_model = [], [], []\n",
    "for i in range(len(body_model_names)):\n",
    "    for j in range(len(tail_model_names)):\n",
    "        for splicing_type in splicing_types:\n",
    "            f1, f2 =  bsm.loss_model(body_model_names[i], body_model_param_names[i]), bsm.loss_model(tail_model_names[j], tail_model_param_names[j])\n",
    "            fs.append(bsm.spliced_loss_model(f1 , f2, splicing_type))\n",
    "            f_names.append(body_model_names[i] +\"_\"+ tail_model_names[j]+\"_\"+splicing_type)\n",
    "            if splicing_type == \"disjoint\": \n",
    "                prior_spliced_model.append(bsm.independent_priors(body_model_priors[i] + tail_model_priors[j] + [γ_prior, p_prior]))\n",
    "            else:\n",
    "                prior_spliced_model.append(bsm.independent_priors(body_model_priors[i] + tail_model_priors[j] + [γ_prior]))  \n",
    "for f in fs:\n",
    "    f.set_ppf()\n",
    "f_spliced_dic = dict(zip(f_names, fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "assigned-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = 2\n",
    "len(fs)/ splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846dbde8-0522-437e-87ae-c4f49ec632d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model batch #0\n"
     ]
    }
   ],
   "source": [
    "popSize, ρ, c, n_step_max, err, paralell, n_proc, verbose = 10000, 1/2, 0.99, 25, 1e-6, False, 4, False\n",
    "def fit_spliced_models(i):\n",
    "    print(f_names[i])\n",
    "    trace, log_marg, DIC, WAIC = bsm.smc_likelihood_annealing(X, fs[i], popSize, prior_spliced_model[i], ρ, c,n_step_max, err, paralell, 4, verbose)\n",
    "    return([trace, log_marg, DIC, WAIC])\n",
    "\n",
    "splits, res = 2, []\n",
    "for k in range(splits):\n",
    "    print(\"Model batch #\"+str(k))\n",
    "    %time res_sub = Parallel(n_jobs=int(len(fs)/splits))(delayed(fit_spliced_models)(i) for i in range(int(k * len(f_names) / splits), int((k+1) * len(f_names)/splits)))\n",
    "    res += res_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53fb2e-7933-4a74-a831-335626a855a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_spliced_models_dic = dict(zip(f_names, res))\n",
    "γ_map = np.array([fit_spliced_models_dic[f_names[k]][0]['γ'].mean() for k in range(len(fit_spliced_models_dic))])\n",
    "spliced_model_df = pd.DataFrame({'model':f_names,\n",
    "                                 \"d\": np.array([f.d for f in fs]),\n",
    "                                 \"γ_map\": np.array([fit_spliced_models_dic[f_names[k]][0]['γ'].mean() for k in range(len(fit_spliced_models_dic))]),\n",
    "                                 'log_marg':  np.array([fit_spliced_models_dic[f_names[k]][1] for k in range(len(fit_spliced_models_dic))]), \n",
    "                                 \"DIC\": np.array([fit_spliced_models_dic[f_names[k]][2] for k in range(len(fit_spliced_models_dic))]), \n",
    "                                 \"WAIC\":np.array([fit_spliced_models_dic[f_names[k]][3] for k in range(len(fit_spliced_models_dic))])})\n",
    "spliced_model_df[\"posterior_probability\"] = np.exp(spliced_model_df[\"log_marg\"] - np.max(spliced_model_df[\"log_marg\"])) / np.sum(np.exp(spliced_model_df[\"log_marg\"] - np.max(spliced_model_df[\"log_marg\"]))) \n",
    "\n",
    "spliced_model_df[\"Wass_dist\"] = np.array([bsm.compute_Wasserstein(X, f_spliced_dic[model_name], fit_spliced_models_dic[model_name][0].mean().values, 1) for model_name in spliced_model_df[\"model\"].values])\n",
    "spliced_model_df.sort_values(by='log_marg', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = spliced_model_df.sort_values(by='Wass_dist', ascending=True)[\"model\"][:6]\n",
    "for model_name in model_names:\n",
    "    f, trace = f_spliced_dic[model_name], fit_spliced_models_dic[model_name][0]\n",
    "    bsm.posterior_plots(f, trace)\n",
    "#     bsm.trace_plots(f, trace)\n",
    "#     bsm.qq_plot(X, f, trace.mean().values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "spliced_model_df.to_csv(\"../../Data/Danish/danish_spliced_models_fixed_threshold.csv\", sep=',')\n",
    "with open('../../Data/Danish/trace_danish_spliced_models_fixed_threshold', 'wb') as fp:\n",
    "    pickle.dump(fit_spliced_models_dic, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-commercial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
